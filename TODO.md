# List of to-do items
0. Change the overall code structural like in imgtools: separate the data structure that stores the features and the FeatureExtractor class (create it) that runs the feature extractor code.
1. Change how the GAP bed file is required to be formatted. Right now it is a bed file with 4 columns, the last beeing a boolean (True for gaps, False for non-gaps). This should be changed to a format more similar to what we were using before. For example, a BED file where the fourth column is a string, with 'cen' for centromerer, 'tel' for telomeres, 'dom' for domains, and so on. I can actually have a list of all possible non-domain keys (e.g. ['cen', 'centromere', 'tel', 'telomere', 'gap', 'contig', 'contigous']) and we would then get True for any of these keys, and False otherwise. This would make the code more flexible and easier to use. I should also store the GAP file in the HDF5 file.
2. Implement Markov clustering. Right now the nuclear bodies structural feature requires as input a pickle file that contains a dictionary, where each key is a structure ID and each value is a numpy array of shape (nbody, 3,) with the coordinates of the center of masses of all nuclear bodies. I have to first change this into a HDF5 file. Then I have to code the Markov clustering algorithm for generating the nuclear bodies from an input BED file (or from the Interior Localization Frequency). And finally I have to decide how to store all of this. I was thinking that I can have a key in the configuration file that specifies how the nuclear bodies should be provided (e.g. 'bodies': 'location_file' or 'markov_clustering') and a key for the file location. Then, if 'bodies' is 'location_file', I can store the coordinates of the nuclear bodies in a HDF5 file. If it's 'markov_clustering', I would store, for each structure ID, both the total markov clustering result (a numpy array of shape (nbead,) of int, where each element is 0 if the bead in that structure has not clustered, or equal to its cluster ID if it has) and the center of masses for each cluster, that would be equivalent to the (nbody, 3,) numpy array I mentioned before. This would allow me to use the same code for both cases, and would make the code more flexible and easier to use.
3. Check parameter specifications. Right now the choices of the parameters required for each structural feature is a bit lousy. It requires the coordinates to be in nanometers, but without any flag, and it doesn't really depend on metris such as resolution, bead radii, and so on. Also, some distances are surface-to-surface, while others are center-to-center. I should make this more consistent and easier to use.
4. Add an analysis module. I don't have to go crazy right away adding a lot of analysis, but I should set the basis of the code. I can probably add:
    - A validation module for comparing ensemble structural features (LaminaDamID, LaminaTSA-seq, SonTSA-seq, NucleoliTSA-seq),
    - PDB file generation color-coded according to a single-cell feature of interest (by the way I have to improve the write_pdb function in alabtools),
    - Log-fold change analysis.
